{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7773bd51-0616-42be-acd8-2e5b4ad6953b",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Instalações necessárias:\n",
    "!pip install tdqm\n",
    "!pip install matplotlib\n",
    "!pip install efficientnet_pytorch\n",
    "!pip install flwr\n",
    "!pip install ray\n",
    "!pip install --upgrade --force-reinstall torch torchvision torchaudio --index-url https://download.pytorch.org/whl/cu118"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "91d7c2b7-49db-4a26-af24-ba05f7dcb339",
   "metadata": {},
   "outputs": [],
   "source": [
    "import warnings\n",
    "from collections import OrderedDict\n",
    "from typing import List, Tuple\n",
    "\n",
    "import flwr as fl\n",
    "from flwr .common import Metrics, Context\n",
    "\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "from torch.utils.data import DataLoader, random_split\n",
    "from torchvision.transforms import Compose, Normalize, ToTensor\n",
    "from torchvision.datasets import ImageFolder, CIFAR10\n",
    "import torchvision.models as models\n",
    "from torchvision import transforms\n",
    "\n",
    "from tqdm import tqdm\n",
    "import random\n",
    "from efficientnet_pytorch import EfficientNet\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "import os\n",
    "import time\n",
    "import numpy as np\n",
    "import datetime"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "638ced13-7df7-4f8c-acb0-46e8653f0936",
   "metadata": {},
   "outputs": [],
   "source": [
    "warnings.filterwarnings(\"ignore\", category=UserWarning)\n",
    "DEVICE = torch.device(\"cuda:0\" if torch.cuda.is_available() else \"cpu\")\n",
    "START = time.time()\n",
    "DATE_NOW = datetime.datetime.now().strftime(\"%Y-%m-%d_%H-%M-%S\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5ac4dfd4-b22a-44c2-96a3-162d40f406ee",
   "metadata": {},
   "outputs": [],
   "source": [
    "def train(net, trainloader, epochs: int, verbose=False):\n",
    "\tcriterion = torch.nn.CrossEntropyLoss()\n",
    "\toptimizer = torch.optim.Adam(net.parameters())\n",
    "\tnet.train()\n",
    "\tfor epoch in range(epochs):\n",
    "\t\tcorrect, total, epoch_loss = 0, 0, 0.0\n",
    "\t\tfor images, labels in trainloader:\n",
    "\t\t\timages, labels = images.to(DEVICE), labels.to(DEVICE)\n",
    "\t\t\toptimizer.zero_grad()\n",
    "\t\t\toutputs = net(images)\n",
    "\t\t\tloss = criterion(net(images), labels)\n",
    "\t\t\tloss.backward()\n",
    "\t\t\toptimizer.step()\n",
    "\t\t\t#metrics\n",
    "\t\t\tepoch_loss += loss\n",
    "\t\t\ttotal += labels.size(0)\n",
    "\t\t\tcorrect += (torch.max(outputs.data, 1)[1] == labels).sum().item()\n",
    "\t\tepoch_loss /= len(trainloader.dataset)\n",
    "\t\tepoch_acc = correct / total\n",
    "\t\tif verbose:\n",
    "\t\t\tprint(f\"Epoch {epoch+1}: train loss {epoch_loss}, accuracy {epoch_acc}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "161199a5-ede1-4c61-8956-24bfd8ae60a8",
   "metadata": {},
   "outputs": [],
   "source": [
    "def test(net, testloader):\n",
    "\tcriterion = torch.nn.CrossEntropyLoss()\n",
    "\tcorrect, total, loss = 0, 0, 0.0\n",
    "\tnet.eval()\n",
    "\twith torch.no_grad():\n",
    "\t\tfor images, labels in testloader:\n",
    "\t\t\timages, labels = images.to(DEVICE), labels.to(DEVICE)\n",
    "\t\t\toutputs = net(images)\n",
    "\t\t\tloss += criterion(outputs, labels).item()\n",
    "\t\t\t_, predicted = torch.max(outputs.data, 1)\n",
    "\t\t\ttotal += labels.size(0)\n",
    "\t\t\tcorrect += (predicted == labels).sum().item()\n",
    "\tloss /= len(testloader.dataset)\n",
    "\taccuracy = correct / total\n",
    "\treturn loss, accuracy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "57a27b2f-d346-4128-94ec-82728afba86d",
   "metadata": {},
   "outputs": [],
   "source": [
    "NUM_CLIENTS=2\n",
    "SEED = 42\n",
    "BATCH_SIZE = 16\n",
    "MODEL = \"alexnet\"\n",
    "NUM_CLASSES = 2\n",
    "#CLASSES =  ('plane', 'car', 'bird', 'cat', 'deer', 'dog', 'frog', 'horse', 'ship', 'truck') #classes do CIFAR10\n",
    "CLASSES = ('benign', 'malignant') #Classes do BreakHis\n",
    "EPOCHS = 10\n",
    "def load_data():\n",
    "    # Load the breast cancer dataset (modify the paths accordingly)\n",
    "    input_size = 224\n",
    "    data_transforms = {\n",
    "        'transform': transforms.Compose([\n",
    "\t\ttransforms.Resize([input_size, input_size], antialias=True),\n",
    "\t\ttransforms.ToTensor(),\n",
    "\t\ttransforms.Normalize([0.485, 0.456, 0.406], [0.229, 0.224, 0.225])\n",
    "\t    ]),\n",
    "        'teste': transforms.Compose([\n",
    "\t\ttransforms.ToTensor(),\n",
    "\t\ttransforms.Normalize((0.5, 0.5, 0.5), (0.5, 0.5, 0.5))\n",
    "\t    ])\n",
    "    }\n",
    "\n",
    "    trainset = ImageFolder(\"./data/train\", transform=data_transforms['transform'])\n",
    "    testset = ImageFolder(\"./data/test\", transform=data_transforms['transform'])\n",
    "    #return DataLoader(trainset, batch_size=BATCH_SIZE, shuffle=True), DataLoader(testset)\n",
    "\n",
    "\n",
    "    # trainset = CIFAR10(\"./dataset\", train=True, download=True, transform=data_transforms['transform'])\n",
    "    # testset = CIFAR10(\"./dataset\", train=False, download=True, transform=data_transforms['transform'])\n",
    "\n",
    "    #Split training set into 10 partitions to simulate the individual dataset\n",
    "    # partition_size = len(trainset) // NUM_CLIENTS\n",
    "    # lengths = [partition_size] * NUM_CLIENTS\n",
    "    \n",
    "    partition_size = len(trainset) // NUM_CLIENTS\n",
    "    remainder = len(trainset) % NUM_CLIENTS\n",
    "    lengths = [partition_size] * (NUM_CLIENTS - 1) + [partition_size + remainder]\n",
    "    datasets = random_split(trainset, lengths, torch.Generator().manual_seed(SEED))\n",
    "\n",
    "    #split each partition into train/val and create DataLoader\n",
    "    trainloaders = []\n",
    "    valloaders = []\n",
    "\n",
    "    for ds in datasets:\n",
    "        len_val = len(ds)//10 # 10% validation set\n",
    "        len_train = len(ds)-len_val\n",
    "        lengths = [len_train, len_val]\n",
    "        ds_train, ds_val = random_split(ds, lengths, torch.Generator().manual_seed(SEED))\n",
    "        trainloaders.append(DataLoader(ds_train, batch_size=BATCH_SIZE, shuffle=True))\n",
    "        valloaders.append(DataLoader(ds_val, batch_size=BATCH_SIZE))\n",
    "    testloaders = DataLoader(testset, batch_size=BATCH_SIZE)\n",
    "\n",
    "    return trainloaders, valloaders, testloaders"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "36417d1c-3177-4b2b-a62d-fabb196a15eb",
   "metadata": {},
   "outputs": [],
   "source": [
    "# class Net(nn.Module):\n",
    "# \tdef __init__(self) -> None:\n",
    "# \t\tsuper(Net, self).__init__()\n",
    "# \t\tself.conv1 = nn.Conv2d(3,6,5)\n",
    "# \t\tself.pool=nn.MaxPool2d(2,2)\n",
    "# \t\tself.conv2 = nn.Conv2d(6, 16, 5)\n",
    "# \t\tself.fc1 = nn.Linear(16*5*5, 120)\n",
    "# \t\tself.fc2 = nn.Linear(120, 84)\n",
    "# \t\tself.fc3 = nn.Linear(84, 10)\n",
    "\t\n",
    "# \tdef forward(self, x: torch.Tensor) -> torch.Tensor:\n",
    "# \t\tx = self.pool(F.relu(self.conv1(x)))\n",
    "# \t\tx = self.pool(F.relu(self.conv2(x)))\n",
    "# \t\tx = x.view(-1, 16 *5 *5)\n",
    "# \t\tx = F.relu(self.fc1(x))\n",
    "# \t\tx = F.relu(self.fc2(x))\n",
    "# \t\tx = self.fc3(x)\n",
    "# \t\treturn x\n",
    "\n",
    "\n",
    "class Net(nn.Module):\n",
    "    def __init__(self, model_name=MODEL) -> None:\n",
    "        super(Net, self).__init__()\n",
    "\n",
    "        if model_name == \"alexnet\":\n",
    "            self.model = models.alexnet(weights='DEFAULT')\n",
    "            num_features = self.model.classifier[6].in_features\n",
    "            self.model.classifier[6] = nn.Linear(num_features, NUM_CLASSES)\n",
    "        elif model_name == \"resnet\":\n",
    "            self.model = models.resnet50(weights='DEFAULT')\n",
    "            num_features = self.model.fc.in_features\n",
    "            self.model.fc = nn.Linear(num_features, NUM_CLASSES) \n",
    "        elif model_name == \"efficientnet\":\n",
    "            self.model = EfficientNet.from_pretrained('efficientnet-b0')\n",
    "            num_features = self.model._fc.in_features\n",
    "            self.model._fc = nn.Linear(num_features, NUM_CLASSES)\n",
    "        else:\n",
    "            raise ValueError(f\"Modelo não suportado: {model_name}\")\n",
    "\n",
    "    def forward(self, x: torch.Tensor) -> torch.Tensor:\n",
    "        return self.model(x)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "15489edb-af68-47bd-adbe-dade5d1b1626",
   "metadata": {},
   "outputs": [],
   "source": [
    "net = Net().to(DEVICE)\n",
    "trainloaders, valloaders, testloader = load_data()\n",
    "trainloader = trainloaders[0]\n",
    "valloader = valloaders[0]\n",
    "\n",
    "loss_per_epoch = []\n",
    "accuracy_per_epoch = []\n",
    "\n",
    "print(f\"Training on {DEVICE} using PyTorch {torch.__version__} and Flower {fl.__version__}\")\n",
    "\n",
    "for epoch in range(EPOCHS):\n",
    "\ttrain(net, trainloader, 1)\n",
    "\tloss, accuracy = test(net, valloader)\n",
    "\tloss_per_epoch.append(loss)\n",
    "\taccuracy_per_epoch.append(accuracy)\n",
    "\tprint(f\"Epoch {epoch+1}: validation loss {loss}, accuracy: {accuracy}\")\n",
    "loss, accuracy = test(net, testloader)\n",
    "loss_per_epoch.append(loss)\n",
    "accuracy_per_epoch.append(accuracy)\n",
    "print(f\"Final test set performance: \\n\\tloss {loss} \\n\\taccuracy {accuracy}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6349f683-53d9-4796-b78c-4c5682f5d491",
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_parameters(net) -> List[np.ndarray]:\n",
    "    return [val.cpu().numpy() for _, val in net.state_dict().items()]\n",
    "\n",
    "def set_parameters(net, parameters: List[np.ndarray]):\n",
    "    params_dict = zip(net.state_dict().keys(), parameters)\n",
    "    state_dict = OrderedDict({k: torch.Tensor(v) for k, v in params_dict})\n",
    "    net.load_state_dict(state_dict, strict=True)\n",
    "\n",
    "class FlowerClient(fl.client.NumPyClient):\n",
    "    def __init__(self, net, trainloader, valloader):\n",
    "        self.net = net\n",
    "        self.trainloader = trainloader\n",
    "        self.valloader = valloader\n",
    "\n",
    "    def get_parameters(self, config):\n",
    "        return get_parameters(self.net)\n",
    "\n",
    "    def fit(self, parameters, config):\n",
    "        set_parameters(self.net, parameters)\n",
    "        train(self.net, self.trainloader, epochs=EPOCHS)\n",
    "        return get_parameters(self.net), len(self.trainloader), {}\n",
    "\n",
    "    def evaluate(self, parameters, config):\n",
    "        set_parameters(self.net, parameters)\n",
    "        loss, accuracy = test(self.net, self.valloader)\n",
    "        return float(loss), len(self.valloader), {\"accuracy\": float(accuracy)}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5bc65c85-1fd2-44be-b0b3-5e7140eaf9d5",
   "metadata": {},
   "outputs": [],
   "source": [
    "trainloaders, valloaders, testloader = load_data()\n",
    "\n",
    "def client_fn(context: Context) -> FlowerClient:\n",
    "    net = Net().to(DEVICE)\n",
    "    partition_id = context.node_config[\"partition-id\"]\n",
    "    num_partitions = context.node_config[\"num-partitions\"]\n",
    "    trainloader = trainloaders[int(partition_id)]\n",
    "    valloader = valloaders [int(partition_id)]\n",
    "    return FlowerClient(net, trainloader, valloader).to_client()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0d7901aa-5a74-4048-8170-b3c2ef573745",
   "metadata": {},
   "outputs": [],
   "source": [
    "NUM_ROUNDS = 1\n",
    "\n",
    "print(f\"Training on {DEVICE} using PyTorch {torch.__version__} and Flower {fl.__version__}\")\n",
    "\n",
    "def weighted_average(metrics: List[Tuple[int, Metrics]]) -> Metrics:\n",
    "  accuracies = [num_examples * m[\"accuracy\"] for num_examples, m in metrics]\n",
    "  examples = [num_examples for num_examples, _ in metrics]\n",
    "  return {\"accuracy\": sum(accuracies)/sum(examples)}\n",
    "\n",
    "#Create FedAVG strategys\n",
    "strategy = fl.server.strategy.FedAvg(\n",
    "    fraction_fit=1.0, #sample 100% of available clients for training\n",
    "    fraction_evaluate=0.5, #sample 50% of available clients for evaluation\n",
    "    min_fit_clients=NUM_ROUNDS, #never sambple less than 10 clients for training\n",
    "    min_evaluate_clients=1, #never sample less than 5 clients for evaluation\n",
    "    min_available_clients=NUM_ROUNDS, #wait until all 10 clients are available\n",
    "    evaluate_metrics_aggregation_fn=weighted_average,\n",
    ")\n",
    "#Start Simulation\n",
    "output = fl.simulation.start_simulation(\n",
    "    client_fn=client_fn,\n",
    "    num_clients =NUM_CLIENTS,\n",
    "    config= fl.server.ServerConfig(num_rounds=NUM_ROUNDS),\n",
    "    strategy=strategy,\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6f841717-65db-4769-82f6-db3ffa049f94",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"Output FL - Loss: \", output.losses_distributed)\n",
    "print(\"Output FL - Accuracy: \", output.metrics_distributed[\"accuracy\"])\n",
    "\n",
    "fl_accuracy = []\n",
    "fl_loss = []\n",
    "\n",
    "for loss in output.losses_distributed:\n",
    "      print(f\"Loss in Round {loss[0]}: {loss[1]}\")\n",
    "      fl_loss.append(loss[1])\n",
    "      \n",
    "\n",
    "for acc in output.metrics_distributed[\"accuracy\"]:\n",
    "      print(f\"Accuracy in Round {acc[0]}: {acc[1]}\")\n",
    "      fl_accuracy.append(acc[1])\n",
    "      \n",
    "fig = plt.figure()\n",
    "ax = plt.axes()\n",
    "\n",
    "x = range(len(fl_loss))\n",
    "ax.plot(x, fl_loss)\n",
    "plt.xlabel(\"Rounds\")\n",
    "plt.ylabel(\"Loss\")\n",
    "\n",
    "fig2 = plt.figure()\n",
    "ax2 = plt.axes()\n",
    "\n",
    "x = range(len(fl_accuracy))\n",
    "ax2.plot(x, fl_accuracy)\n",
    "plt.xlabel(\"Rounds\")\n",
    "plt.ylabel(\"Accuracy\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.19"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
